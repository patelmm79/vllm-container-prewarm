# Hugging Face Token (required for downloading models during build)
HF_TOKEN=your_hugging_face_token_here

# Model Configuration
MODEL_NAME=google/gemma-3-1b-it
HF_HOME=/model-cache

# Server Configuration
PORT=8000
# MAX_MODEL_LEN=2048  # Optional: Set maximum model length

# CUDA Architecture Configuration
# This setting is optimized for Google Cloud Run which uses NVIDIA T4 GPUs
# NVIDIA T4 has compute capability 7.5
# Setting this reduces compilation time by avoiding compilation for all GPU architectures
TORCH_CUDA_ARCH_LIST=7.5

# Common GPU compute capabilities for reference:
# - NVIDIA T4 (Cloud Run): 7.5
# - NVIDIA V100: 7.0
# - NVIDIA A100: 8.0
# - NVIDIA H100: 9.0
# - RTX 3090/4090: 8.6
# - RTX 4000 series Ada: 8.9
